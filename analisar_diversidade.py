#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analisa diversidade das amostras ML
Identifica se dados s√£o muito similares
"""

import json
import numpy as np
from pathlib import Path
from collections import Counter

def analisar_diversidade():
    """Analisa diversidade das amostras coletadas"""
    
    data_path = Path("ml_models/training_data.json")
    
    if not data_path.exists():
        print("‚ùå Dados de treino n√£o encontrados!")
        print("   Execute o bot primeiro para coletar amostras")
        return
    
    # Carrega dados JSON
    with open(data_path, 'r', encoding='utf-8') as f:
        samples = json.load(f)
    
    if not samples or len(samples) == 0:
        print("‚ùå Nenhuma amostra encontrada!")
        return
    
    # Converte para arrays numpy
    X = []
    y = []
    
    for sample in samples:
        # Features baseadas na estrutura real
        features = [
            sample.get('hour', 0),
            sample.get('minute', 0),
            sample.get('pos_x', 0),
            sample.get('pos_y', 0),
            sample.get('sector_N', 0),
            sample.get('sector_E', 0),
            sample.get('sector_S', 0),
            sample.get('sector_W', 0),
            sample.get('enemy_count', 0),
        ]
        X.append(features)
        
        # Label baseado na contagem de inimigos (proxy para a√ß√£o)
        enemy_count = sample.get('enemy_count', 0)
        if enemy_count == 0:
            label = 0  # Explorar
        elif enemy_count <= 2:
            label = 1  # Combate √∫nico
        else:
            label = 2  # AOE/Multi-target
        
        y.append(label)
    
    X = np.array(X)
    y = np.array(y)
    
    print("\n" + "="*70)
    print("üìä AN√ÅLISE DE DIVERSIDADE DOS DADOS ML")
    print("="*70)
    
    print(f"\nüìà Total de amostras: {len(X)}")
    print(f"   Features por amostra: {X.shape[1]}")
    
    # An√°lise de labels
    print("\nüè∑Ô∏è  DISTRIBUI√á√ÉO DE LABELS:")
    label_counts = Counter(y)
    for label, count in sorted(label_counts.items()):
        pct = (count / len(y)) * 100
        bar = "‚ñà" * int(pct / 2)
        print(f"   Classe {label}: {count:4d} ({pct:5.1f}%) {bar}")
    
    # An√°lise de unicidade
    print("\nüîç AN√ÅLISE DE UNICIDADE:")
    
    # Amostras √∫nicas
    X_unique = np.unique(X, axis=0)
    pct_unique = (len(X_unique) / len(X)) * 100
    
    print(f"   Amostras √∫nicas: {len(X_unique)} de {len(X)} ({pct_unique:.1f}%)")
    
    if pct_unique < 50:
        print("   ‚ö†Ô∏è  MUITAS DUPLICADAS! Dados repetitivos!")
    elif pct_unique < 80:
        print("   ‚ö†Ô∏è  Diversidade moderada. Pode melhorar.")
    else:
        print("   ‚úÖ Boa diversidade!")
    
    # An√°lise de vari√¢ncia
    print("\nüìä VARI√ÇNCIA DAS FEATURES:")
    
    variances = np.var(X, axis=0)
    mean_var = np.mean(variances)
    
    print(f"   Vari√¢ncia m√©dia: {mean_var:.4f}")
    
    # Features com baixa vari√¢ncia (pouco √∫teis)
    low_var_features = np.sum(variances < 0.01)
    pct_low_var = (low_var_features / len(variances)) * 100
    
    print(f"   Features com baixa vari√¢ncia: {low_var_features} ({pct_low_var:.1f}%)")
    
    if pct_low_var > 30:
        print("   ‚ö†Ô∏è  Muitas features n√£o variam!")
    
    # An√°lise de correla√ß√£o entre amostras
    print("\nüîó AN√ÅLISE DE SIMILARIDADE:")
    
    # Pega 1000 amostras aleat√≥rias para an√°lise
    sample_size = min(1000, len(X))
    indices = np.random.choice(len(X), sample_size, replace=False)
    X_sample = X[indices]
    
    # Calcula dist√¢ncias m√©dias
    distances = []
    for i in range(min(100, len(X_sample))):
        for j in range(i+1, min(i+10, len(X_sample))):
            dist = np.linalg.norm(X_sample[i] - X_sample[j])
            distances.append(dist)
    
    mean_dist = np.mean(distances)
    std_dist = np.std(distances)
    
    print(f"   Dist√¢ncia m√©dia entre amostras: {mean_dist:.4f}")
    print(f"   Desvio padr√£o: {std_dist:.4f}")
    
    if mean_dist < 1.0:
        print("   ‚ö†Ô∏è  Amostras muito SIMILARES!")
        print("   Sugest√£o: Farmar em √°reas/condi√ß√µes diferentes")
    elif mean_dist < 5.0:
        print("   ‚ö†Ô∏è  Similaridade moderada")
    else:
        print("   ‚úÖ Boa varia√ß√£o entre amostras!")
    
    # Recomenda√ß√µes
    print("\n" + "="*70)
    print("üí° RECOMENDA√á√ïES:")
    print("="*70)
    
    problemas = []
    
    if pct_unique < 50:
        problemas.append("duplicatas")
        print("\n1. üîÑ REDUZIR DUPLICATAS:")
        print("   ‚Ä¢ Farmar em √°reas diferentes")
        print("   ‚Ä¢ Variar hor√°rios (manh√£/tarde/noite)")
        print("   ‚Ä¢ Testar diferentes estrat√©gias de combate")
    
    if pct_low_var > 30:
        problemas.append("features constantes")
        print("\n2. üìä AUMENTAR VARIA√á√ÉO:")
        print("   ‚Ä¢ Usar diferentes skills")
        print("   ‚Ä¢ Alterar padr√µes de movimento")
        print("   ‚Ä¢ Farmar mobs de diferentes n√≠veis")
    
    if mean_dist < 1.0:
        problemas.append("amostras similares")
        print("\n3. üéØ DIVERSIFICAR FARMING:")
        print("   ‚Ä¢ Alternar entre 3+ √°reas diferentes")
        print("   ‚Ä¢ Testar solo vs party")
        print("   ‚Ä¢ Variar targets (single vs AOE)")
    
    if not problemas:
        print("\n‚úÖ DADOS COM BOA QUALIDADE!")
        print("   Continue coletando em diferentes condi√ß√µes")
    
    # An√°lise de clusters recomendados
    print("\n" + "="*70)
    print("üéØ N√öMERO IDEAL DE CLUSTERS:")
    print("="*70)
    
    n_unique_patterns = len(X_unique)
    
    if n_unique_patterns < 10:
        print(f"   Recomendado: 2 clusters (apenas {n_unique_patterns} padr√µes √∫nicos)")
        print("   ‚ö†Ô∏è  Precisa coletar dados mais variados!")
    elif n_unique_patterns < 50:
        print(f"   Recomendado: 2-3 clusters ({n_unique_patterns} padr√µes √∫nicos)")
    elif n_unique_patterns < 200:
        print(f"   Recomendado: 3-5 clusters ({n_unique_patterns} padr√µes √∫nicos)")
    else:
        print(f"   Recomendado: 5-10 clusters ({n_unique_patterns} padr√µes √∫nicos)")
        print("   ‚úÖ Dados diversificados!")
    
    print("\n" + "="*70)
    
    # Retorna m√©tricas
    return {
        'total_samples': len(X),
        'unique_samples': len(X_unique),
        'pct_unique': pct_unique,
        'mean_variance': mean_var,
        'mean_distance': mean_dist,
        'recommended_clusters': min(3, max(2, n_unique_patterns // 50))
    }


def sugerir_plano_coleta():
    """Sugere plano para coletar dados mais diversos"""
    
    print("\n" + "="*70)
    print("üìã PLANO DE COLETA DIVERSIFICADA")
    print("="*70)
    
    print("\nüéØ OBJETIVO: Coletar 1.000 amostras VARIADAS")
    print("\nüìÖ ROTEIRO (4 sess√µes de 1h):\n")
    
    print("SESS√ÉO 1 - √Årea Principal (30min)")
    print("  ‚Ä¢ Sua √°rea atual de farming")
    print("  ‚Ä¢ Meta: 200 amostras")
    print("  ‚Ä¢ Foco: Estabelecer baseline\n")
    
    print("SESS√ÉO 2 - √Årea Alternativa 1 (30min)")
    print("  ‚Ä¢ Mobs diferentes (outro n√≠vel/tipo)")
    print("  ‚Ä¢ Meta: 200 amostras")
    print("  ‚Ä¢ Foco: Diversidade de combate\n")
    
    print("SESS√ÉO 3 - √Årea Alternativa 2 (30min)")
    print("  ‚Ä¢ Terreno diferente (cave/outdoor/dungeon)")
    print("  ‚Ä¢ Meta: 200 amostras")
    print("  ‚Ä¢ Foco: Varia√ß√£o de ambiente\n")
    
    print("SESS√ÉO 4 - Mix Estrat√©gias (30min)")
    print("  ‚Ä¢ Alterna entre todas as √°reas")
    print("  ‚Ä¢ Meta: 400 amostras")
    print("  ‚Ä¢ Foco: Adaptabilidade\n")
    
    print("‚úÖ RESULTADO ESPERADO:")
    print("  ‚Ä¢ 1.000 amostras diversificadas")
    print("  ‚Ä¢ 3-5 padr√µes distintos")
    print("  ‚Ä¢ ML aprende diferentes contextos")
    print("  ‚Ä¢ Performance > 120% bot nativo")
    
    print("\n" + "="*70)


if __name__ == "__main__":
    metricas = analisar_diversidade()
    
    if metricas and metricas['pct_unique'] < 70:
        print("\n")
        sugerir_plano_coleta()
